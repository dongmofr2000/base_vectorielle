# ====================================================================
#              PROJET RAG (RETRIEVAL-AUGMENTED GENERATION)
# ====================================================================

# üåü Pr√©sentation du Projet
# -------------------------
# Ce projet impl√©mente un syst√®me de G√©n√©ration Augment√©e par R√©cup√©ration (RAG) simplifi√©.
# L'objectif est de fournir √† un Grand Mod√®le de Langage (LLM) un contexte pertinent 
# (r√©cup√©r√© d'une base de connaissances locale) avant de g√©n√©rer une r√©ponse.

# Le syst√®me est divis√© en deux √©tapes :
# 1. Indexation : Cr√©ation d'un index vectoriel FAISS √† partir du document source (evenements_reels.txt).
# 2. R√©cup√©ration : Recherche des morceaux de texte les plus similaires √† une requ√™te utilisateur.

# üîß Instructions pour la Reproduction
# ------------------------------------

# √âtape 1 : Installation des D√©pendances
# Vous devez avoir Python (3.8+) et installer les biblioth√®ques suivantes :
# pip install langchain-community langchain-core langchain-huggingface langchain-text-splitters faiss-cpu

# √âtape 2 : Indexation (Cr√©ation de la Base de Connaissances)
# Lancez le script vector_indexer.py. Il va lire evenements_reels.txt, le d√©couper,
# cr√©er les embeddings, et sauvegarder l'index vectoriel FAISS dans un dossier ./faiss_index.
# COMMANDE : python vector_indexer.py

# √âtape 3 : R√©cup√©ration (Interrogation de l'Index)
# Une fois l'index cr√©√©, lancez le script .\venv\Scripts\python.exe chat_rag.py --doc evenements_reels.pdf. Il chargera l'index et recherchera
# les 3 morceaux de texte les plus pertinents pour r√©pondre √† la question.
# COMMANDE : .\venv\Scripts\python.exe chat_rag.py --doc evenements_reels.pdf

# ====================================================================
#              FIN DU CONTENU README
# ====================================================================
